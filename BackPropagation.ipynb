{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luJ8b1N2t5_U"
      },
      "source": [
        "Name: Gadisa Amenu\n",
        "\n",
        "ID: UGR/8440/12\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "id": "blA5esJtdFVP"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rurwL-W2PoIN"
      },
      "source": [
        "## Creating Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "id": "owY9mN1oPAal"
      },
      "outputs": [],
      "source": [
        "class DenseLayer:\n",
        "  # Layer initialization\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    # Initialize weights and biases\n",
        "    self.weights = 0.01 * torch.rand(n_inputs, n_neurons)\n",
        "    self.biases = torch.zeros((1, n_neurons))\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    # Calculate output values from inputs, weights and biases\n",
        "    self.output = torch.matmul(inputs, self.weights) + self.biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajjr0QcUP8tA"
      },
      "source": [
        "## Activation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CfScOYgaorz"
      },
      "source": [
        "### Linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "id": "6DWvh3nttY2B"
      },
      "outputs": [],
      "source": [
        "class Activation_Linear:\n",
        "  # Forward pass\n",
        "  def forward(self,input):\n",
        "    self.output = input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqX_24EntYTU",
        "outputId": "452382c9-f378-4236-c183-7fd9e9b3f220"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.3220,  0.0926,  0.0204],\n",
              "        [ 0.1194,  0.1129, -0.2730]])"
            ]
          },
          "execution_count": 288,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = Activation_Linear()\n",
        "x.forward(torch.rand(2,3)-0.5)\n",
        "x.output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh2w_sCks92x"
      },
      "source": [
        "### ReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "id": "6owCQofBP_iL"
      },
      "outputs": [],
      "source": [
        "class Activation_ReLU:\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    self.output = torch.max(torch.tensor(0),inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_F8P2ziStfr",
        "outputId": "9b5d1565-8447-4663-f47d-fee9c2cb4376"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0201, 0.3624, 0.3215],\n",
              "        [0.0000, 0.0753, 0.0000]])"
            ]
          },
          "execution_count": 290,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = Activation_ReLU()\n",
        "x.forward(torch.rand(2,3)-0.5)\n",
        "x.output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E-apHeQahmI"
      },
      "source": [
        "### Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "id": "nlf-0k4OaffJ"
      },
      "outputs": [],
      "source": [
        "class Activation_Sigmoid:\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    self.output = 1 / (1 + torch.exp(inputs*-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bO3ocTzQdCoh",
        "outputId": "689ebeaa-0439-498a-8ad0-4971102a3b62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.6475, 0.7034, 0.5206],\n",
              "        [0.5528, 0.6356, 0.5559]])"
            ]
          },
          "execution_count": 292,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = Activation_Sigmoid()\n",
        "x.forward(torch.rand(2,3))\n",
        "x.output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQrWxiXBax30"
      },
      "source": [
        "### Softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {
        "id": "wF2Lf9ESTOOU"
      },
      "outputs": [],
      "source": [
        "class Activation_Softmax:\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    # Get unnormalized probabilities\n",
        "    exp_values = torch.exp(inputs - torch.max(inputs, axis=1, keepdim=True).values)\n",
        "    # Normalize them for each sample\n",
        "    probabilities = exp_values / torch.sum(exp_values, axis=1, keepdim=True)\n",
        "    self.output = probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q72wA_KFZUoZ",
        "outputId": "e45acfee-d02f-439d-cd7e-62870f8ca9f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2994, 0.4913, 0.2094],\n",
            "        [0.3211, 0.3651, 0.3137]])\n",
            "tensor([[1.0000],\n",
            "        [1.0000]])\n"
          ]
        }
      ],
      "source": [
        "x = Activation_Softmax()\n",
        "x.forward(torch.rand(2,3))\n",
        "print(x.output)\n",
        "print(torch.sum(x.output,axis=1,keepdim=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4D0Dsk5EXiu"
      },
      "source": [
        "\n",
        "#### BackPropagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "id": "7FZ7Pk0gIK8v"
      },
      "outputs": [],
      "source": [
        "X = torch.tensor([0.1, 0.5])\n",
        "y = torch.tensor([0.04, 0.75])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "id": "Cb5W0woZRU9_"
      },
      "outputs": [],
      "source": [
        "hidden_layer_1 = DenseLayer(2, 4)\n",
        "activation1 =  Activation_Sigmoid()\n",
        "output_layer = DenseLayer(4, 2)\n",
        "# activation2 = Activation_Linear()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {
        "id": "WAoeJRRJRArn"
      },
      "outputs": [],
      "source": [
        "def forward_pass(X):\n",
        "  hidden_layer_1.forward(X)\n",
        "  activation1.forward(hidden_layer_1.output)\n",
        "  output_layer.forward(activation1.output)\n",
        "  # activation2.forward(output_layer.output)\n",
        "  return output_layer.output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {
        "id": "cJePM510S1HH"
      },
      "outputs": [],
      "source": [
        "def back_prop(fp):\n",
        "  lr = torch.tensor(0.01)\n",
        "\n",
        "  back1 = (-y[0] + fp[0][0])\n",
        "  back2 = (-y[1] + fp[0][1])\n",
        "\n",
        "\n",
        "\n",
        "  output_layer.weights[0][0] -= lr * back1*activation1.output[0][0]\n",
        "  output_layer.weights[0][1] -= lr * back2*activation1.output[0][0]\n",
        "\n",
        "  output_layer.weights[1][0] -= lr * back1*activation1.output[0][1]\n",
        "  output_layer.weights[1][1] -= lr * back2*activation1.output[0][1]\n",
        "\n",
        "  output_layer.weights[2][0] -= lr * back1*activation1.output[0][2]\n",
        "  output_layer.weights[2][1] -= lr * back2*activation1.output[0][2]\n",
        "\n",
        "  output_layer.weights[3][0] -= lr * back1*activation1.output[0][3]\n",
        "  output_layer.weights[3][1] -= lr * back2*activation1.output[0][3]\n",
        "\n",
        "  output_layer.biases[0][0] -= lr * back1\n",
        "  output_layer.biases[0][1] -= lr * back2\n",
        "\n",
        "  activation1_derivative_1 = activation1.output[0][0]*( 1 - activation1.output[0][0])\n",
        "  activation1_derivative_2 = activation1.output[0][1]*( 1 - activation1.output[0][1])\n",
        "  activation1_derivative_3 = activation1.output[0][2]*( 1 - activation1.output[0][2])\n",
        "  activation1_derivative_4 = activation1.output[0][3]*( 1 - activation1.output[0][3])\n",
        "\n",
        "  hidden_layer_1.weights[0][0] -= lr * (back1 * output_layer.weights[0][0] + back2 * output_layer.weights[0][1]) * activation1_derivative_1 * X[0]\n",
        "  hidden_layer_1.weights[1][0] -= lr * (back1 * output_layer.weights[0][0] + back2 * output_layer.weights[0][1]) * activation1_derivative_1 * X[1]\n",
        "\n",
        "  hidden_layer_1.weights[0][1] -= lr * (back1 * output_layer.weights[1][0] + back2 * output_layer.weights[1][1]) * activation1_derivative_2 * X[0]\n",
        "  hidden_layer_1.weights[1][1] -= lr * (back1 * output_layer.weights[1][0] + back2 * output_layer.weights[1][1]) * activation1_derivative_2 * X[1]\n",
        "\n",
        "  hidden_layer_1.weights[0][2] -= lr * (back1 * output_layer.weights[2][0] + back2 * output_layer.weights[2][1]) * activation1_derivative_3  * X[0]\n",
        "  hidden_layer_1.weights[1][2] -= lr * (back1 * output_layer.weights[2][0] + back2 * output_layer.weights[2][1]) * activation1_derivative_3  * X[1]\n",
        "\n",
        "  hidden_layer_1.weights[0][3] -= lr * (back1 * output_layer.weights[3][0] + back2 * output_layer.weights[3][1]) * activation1_derivative_4 * X[0]\n",
        "  hidden_layer_1.weights[1][3] -= lr * (back1 * output_layer.weights[3][0] + back2 * output_layer.weights[3][1]) * activation1_derivative_4 * X[1]\n",
        "\n",
        "  hidden_layer_1.biases[0][0] -= lr * (back1 * output_layer.weights[0][0] + back2 * output_layer.weights[0][1]) * activation1_derivative_1\n",
        "  hidden_layer_1.biases[0][1] -= lr * (back1 * output_layer.weights[1][0] + back2 * output_layer.weights[1][1]) * activation1_derivative_2\n",
        "  hidden_layer_1.biases[0][2] -= lr * (back1 * output_layer.weights[2][0] + back2 * output_layer.weights[2][1]) * activation1_derivative_3\n",
        "  hidden_layer_1.biases[0][3] -= lr * (back1 * output_layer.weights[3][0] + back2 * output_layer.weights[3][1]) * activation1_derivative_4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {
        "id": "RzJ7jkxaTs8D"
      },
      "outputs": [],
      "source": [
        "def error_calculation(y_true, y_pred):\n",
        "  return torch.mean(0.5*(y_true - y_pred)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {
        "id": "cNKQBlGWTgDz"
      },
      "outputs": [],
      "source": [
        "loss = 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taOHtItDTR28",
        "outputId": "4f29529f-192f-4981-bc90-250ae64e1681"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial loss: tensor(0.1381)\n",
            "Initial prediction: tensor([[0.0090, 0.0075]])\n",
            "Final loss: tensor(9.7415e-05)\n",
            "Final prediction: tensor([[0.0392, 0.7303]])\n",
            "Target value: tensor([0.0400, 0.7500])\n"
          ]
        }
      ],
      "source": [
        "y_pred = forward_pass(X)\n",
        "err = error_calculation(y, y_pred)\n",
        "print(\"Initial loss:\", err)\n",
        "print(\"Initial prediction:\",y_pred)\n",
        "while err > loss:\n",
        "  back_prop(y_pred)\n",
        "  y_pred = forward_pass(X)\n",
        "  err = error_calculation(y, y_pred)\n",
        "\n",
        "print(\"Final loss:\", err)\n",
        "print(\"Final prediction:\",y_pred)\n",
        "print(\"Target value:\",y)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
